import os
import logging
import asyncio
import google.generativeai as genai
from aiogram import Bot, Dispatcher, types
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.filters import Command
from aiogram.enums.chat_action import ChatAction
from dotenv import load_dotenv

load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
ADMIN_ID = int(os.getenv("ADMIN_ID", "0"))

GEMINI_FAST_MODEL = os.getenv("GEMINI_FAST_MODEL", "models/gemini-2.0-pro-exp-02-05")
GEMINI_SMART_MODEL = os.getenv("GEMINI_SMART_MODEL", "models/gemini-2.0-flash-thinking-exp-1219")

genai.configure(api_key=GEMINI_API_KEY)
logging.basicConfig(level=logging.INFO)

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

start_keyboard = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text="ðŸ”„ Ð—Ð°Ð´Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ AI")],
        [KeyboardButton(text="âš¡ Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ"), KeyboardButton(text="ðŸ§  Ð£Ð¼Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ")]
    ],
    resize_keyboard=True
)

user_model_choice = GEMINI_FAST_MODEL
user_requests = {}  # Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¿Ð¾ user_id
MAX_REQUESTS = 10

def get_gemini_response(prompt: str, model_name: str) -> str:
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        return response.text if response.text else "ÐžÑˆÐ¸Ð±ÐºÐ°: AI Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚."
    except Exception as e:
        logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ðº Gemini ({model_name}): {e}, Ð—Ð°Ð¿Ñ€Ð¾Ñ: {prompt}")
        return "ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ."

@dp.message(Command("start"))
async def send_welcome(message: types.Message):
    await message.answer("ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Ð±Ð¾Ñ‚ Ñ AI Gemini. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ!", reply_markup=start_keyboard)

@dp.message(lambda message: message.text in ["âš¡ Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ", "ðŸ§  Ð£Ð¼Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ"])
async def choose_model(message: types.Message):
    global user_model_choice
    user_model_choice = GEMINI_FAST_MODEL if message.text == "âš¡ Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ" else GEMINI_SMART_MODEL
    await message.answer(f"Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð° {message.text}.")

@dp.message(Command("history"))
async def send_history(message: types.Message):
    if message.from_user.id != ADMIN_ID:
        await message.answer("Ð£ Ñ‚ÐµÐ±Ñ Ð½ÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº ÑÑ‚Ð¾Ð¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ.")
        return

    history = user_requests.get(message.from_user.id, [])
    history_text = "\n".join(history) or "Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¿ÑƒÑÑ‚Ð°."
    await message.answer(f"ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹:\n{history_text}")

@dp.message()
async def handle_message(message: types.Message):
    if message.text.startswith("/"):
        return  # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°Ð²Ð°Ñ‚ÑŒ Ð¸Ñ… Ð² AI

    user_id = message.from_user.id
    user_requests.setdefault(user_id, []).append(message.text)

    if len(user_requests[user_id]) > MAX_REQUESTS:
        user_requests[user_id].pop(0)

    await bot.send_chat_action(message.chat.id, action=ChatAction.TYPING)
    ai_response = get_gemini_response(message.text, user_model_choice)
    await message.answer(ai_response)

async def main():
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
